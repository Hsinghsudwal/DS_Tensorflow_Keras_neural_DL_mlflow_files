{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RtCS-mox_Bkk"
      },
      "outputs": [],
      "source": [
        "# MLflow, Quick Start"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZ6zAjHg_MOw",
        "outputId": "7137a060-330d-44e0-e314-b0f09cc83c51"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-2.16.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting mlflow-skinny==2.16.0 (from mlflow)\n",
            "  Downloading mlflow_skinny-2.16.0-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.5)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
            "  Downloading alembic-1.13.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.3-py2.py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7.1)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.26.4)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.1.4)\n",
            "Requirement already satisfied: pyarrow<18,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (14.0.2)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.3.2)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.13.1)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.32)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.4)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.16.0->mlflow) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.16.0->mlflow) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.16.0->mlflow) (2.2.1)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.16.0->mlflow)\n",
            "  Downloading databricks_sdk-0.32.0-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting gitpython<4,>=3.1.9 (from mlflow-skinny==2.16.0->mlflow)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.16.0->mlflow) (8.4.0)\n",
            "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==2.16.0->mlflow)\n",
            "  Downloading opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==2.16.0->mlflow)\n",
            "  Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.16.0->mlflow) (24.1)\n",
            "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.16.0->mlflow) (3.20.3)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.16.0->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.16.0->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.16.0->mlflow) (0.5.1)\n",
            "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker<8,>=4.0.0->mlflow) (2.0.7)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.0.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.4-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting aniso8601<10,>=8 (from graphene<4->mlflow)\n",
            "  Downloading aniso8601-9.0.1-py2.py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.3)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.10/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.0->mlflow) (2.27.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny==2.16.0->mlflow)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.16.0->mlflow) (3.20.1)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.16.0->mlflow)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.16.0->mlflow)\n",
            "  Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib<4->mlflow) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.16.0->mlflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.16.0->mlflow) (3.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.16.0->mlflow) (2024.8.30)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.16.0->mlflow) (1.16.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.16.0->mlflow)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.0->mlflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.0->mlflow) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.0->mlflow) (0.6.0)\n",
            "Downloading mlflow-2.16.0-py3-none-any.whl (26.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.6/26.6 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-2.16.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.3-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.32.0-py3-none-any.whl (551 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m552.0/552.0 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.4-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: aniso8601, smmap, Mako, gunicorn, graphql-core, deprecated, opentelemetry-api, graphql-relay, gitdb, docker, alembic, opentelemetry-semantic-conventions, graphene, gitpython, databricks-sdk, opentelemetry-sdk, mlflow-skinny, mlflow\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.2 aniso8601-9.0.1 databricks-sdk-0.32.0 deprecated-1.2.14 docker-7.1.0 gitdb-4.0.11 gitpython-3.1.43 graphene-3.3 graphql-core-3.2.4 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-2.16.0 mlflow-skinny-2.16.0 opentelemetry-api-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 smmap-5.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow server --host 127.0.0.1 --port 8080"
      ],
      "metadata": {
        "id": "Mx-0ZS0U_QWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import sklearn library\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "\n",
        "# Define parameters\n",
        "params = {\n",
        "    \"alpha\": 1.0,\n",
        "    \"fit_intercept\": True,\n",
        "    \"solver\": \"auto\",\n",
        "}\n",
        "\n",
        "# Instantiate the Ridge model with parameters\n",
        "ridge = Ridge(**params)\n",
        "\n",
        "# Train the model\n",
        "ridge.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "predictions = ridge.predict(X_test)\n",
        "\n",
        "# Evaluate your model\n",
        "mae, mse, rmse, r_squared = evaluation(y_test, predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "HNqsR4qM_Tja",
        "outputId": "958bca57-1748-480a-fe99-038dec2e0c1b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5d93868671ef>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mridge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the library\n",
        "import mlflow\n",
        "\n",
        "# Connect to the MLflow server (in this case, we are using our own computer)\n",
        "mlflow.set_tracking_uri(uri=\"http://localhost:8080\")\n",
        "\n",
        "# Set the tracking experiment (in this case, House Prices is going to be our experiment name)\n",
        "mlflow.set_experiment(\"House Prices\")"
      ],
      "metadata": {
        "id": "-4TbuqQH_YZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start an MLflow run\n",
        "with mlflow.start_run(run_name=run_name):\n",
        "\n",
        "  ####### The format has to be json #######\n",
        "  ''' Selected data can be uploaded at the same time'''\n",
        "\n",
        "  # Log the hyperparameters\n",
        "  mlflow.log_params(params)\n",
        "\n",
        "  # Log the loss metric\n",
        "  mlflow.log_metrics(metric_eval)\n",
        "\n",
        "\n",
        "  ####### The format has to be int or float #######\n",
        "  ''' Selected data can be uploaded one by one'''\n",
        "\n",
        "  # Log a hyperparameter\n",
        "  mlflow.log_param(\"lr\", 0.001)\n",
        "\n",
        "  # Log a loss metric\n",
        "  mlflow.log_metric(\"val_loss\", val_loss)\n",
        "\n",
        "\n",
        "  ####### Log the model #######\n",
        "\n",
        "  # Infer the model signature\n",
        "  signature = infer_signature(X_train, model.predict(X_train))\n",
        "\n",
        "  # Log the model\n",
        "  model_info = mlflow.sklearn.log_model( # Depends on the framework -> mlflow.pytorch, mlflow.spark...\n",
        "      sk_model=model,\n",
        "      artifact_path=\"hose-price\",\n",
        "      signature=signature,\n",
        "      input_example=X_train,\n",
        "  )\n",
        "\n",
        "\n",
        "  # Set a tag that we can use to remind ourselves what this run was for\n",
        "  mlflow.set_tag(\"Training Info\", \"Basic Ridge model for house prices\")"
      ],
      "metadata": {
        "id": "bB9nfbuMASo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.enable_system_metrics_logging()"
      ],
      "metadata": {
        "id": "f7kpfFueAS8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################ log image ######################\n",
        "\n",
        "# Read the image file back into a variable\n",
        "correlation_matrix_image = Image.open('correlation_matrix.png')\n",
        "\n",
        "# Log the correlation matrix image as an artifact\n",
        "mlflow.log_image(correlation_matrix_image, \"correlation_matrix.png\")\n",
        "\n",
        "\n",
        "############### log dataset #####################\n",
        "\n",
        "dataset_train = mlflow.data.from_pandas(X_train, \"training_data\")\n",
        "mlflow.log_input(dataset_train, context=\"training\")"
      ],
      "metadata": {
        "id": "I8B_AxNkATCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optuna\n",
        "def register_model_mlflow(run_name, params, model, X_train, X_test, y_train, y_test):\n",
        "    \"\"\"\n",
        "    Registers a trained machine learning model and its associated artifacts with MLflow.\n",
        "\n",
        "    Parameters:\n",
        "        run_name (str): Name of the MLflow run.\n",
        "        params (dict): Hyperparameters used for training the model.\n",
        "        model (sklearn.base.BaseEstimator): Trained machine learning model.\n",
        "        X_train (pandas.DataFrame): Features of the training dataset.\n",
        "        X_test (pandas.DataFrame): Features of the testing dataset.\n",
        "        y_train (pandas.Series): Target variable\n",
        "\t of the training dataset.\n",
        "        y_test (pandas.Series): Target variable of the testing dataset.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Trained model instance and evaluation metrics.\n",
        "\n",
        "    \"\"\"\n",
        "    with mlflow.start_run(run_name=run_name):\n",
        "        # Instantiate the model with specified hyperparameters\n",
        "        model_instance = model(**params)\n",
        "        model_instance.fit(X_train, y_train)\n",
        "        predictions = model_instance.predict(X_test)\n",
        "\n",
        "        # Evaluate the model\n",
        "        mae, mse, rmse, r_squared = evaluation(y_test, predictions)\n",
        "\n",
        "        # Log predictions as a table\n",
        "        prediction_table = X_test.copy()\n",
        "        prediction_table[\"ground_truth\"] = y_test\n",
        "        prediction_table[\"predictions\"] = predictions\n",
        "        mlflow.log_table(data=prediction_table, artifact_file=\"predictions.csv\")\n",
        "\n",
        "        # Log evaluation metrics\n",
        "        metric_eval = {\"MAE\": mae, \"MSE\": mse, \"RMSE\": rmse, \"R2 Score\": r_squared}\n",
        "        mlflow.log_metrics(metric_eval)\n",
        "\n",
        "        # Log hyperparameters\n",
        "        mlflow.log_params(params)\n",
        "\n",
        "        # Set a tag to describe the training\n",
        "        mlflow.set_tag(\"Training Info\", \"Basic Ridge model for house prices\")\n",
        "\n",
        "        # Log the trained model\n",
        "        signature = infer_signature(X_train, model_instance.predict(X_train))\n",
        "        model_artifact_path = \"ridge_model\"\n",
        "        mlflow.sklearn.log_model(\n",
        "            sk_model=model_instance,\n",
        "            artifact_path=model_artifact_path,\n",
        "            signature=signature,\n",
        "            input_example=X_train,\n",
        "        )\n",
        "\n",
        "        # Log an image as an artifact\n",
        "        correlation_matrix_image = Image.open('correlation_matrix.png')\n",
        "        mlflow.log_image(correlation_matrix_image, \"correlation_matrix.png\")\n",
        "\n",
        "        # Log the datasets\n",
        "        train_dataset = mlflow.data.from_pandas(X_train, \"training_data\")\n",
        "        mlflow.log_input(train_dataset, context=\"training\")\n",
        "        test_dataset = mlflow.data.from_pandas(X_test, \"test_data\")\n",
        "        mlflow.log_input(test_dataset, context=\"test\")\n",
        "\n",
        "        return model_instance, metric_eval"
      ],
      "metadata": {
        "id": "0ZTOGJf8ATJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hypertuning\n",
        "def objective(trial):\n",
        "    \"\"\"\n",
        "    Objective function for hyperparameter optimization.\n",
        "\n",
        "    Args:\n",
        "        trial (optuna.trial.Trial): A single optimization trial.\n",
        "\n",
        "    Returns:\n",
        "        float: Root mean squared error (RMSE) metric for the Ridge regression model.\n",
        "    \"\"\"\n",
        "    # Define hyperparameters to be optimized\n",
        "    params = {\n",
        "        \"alpha\": trial.suggest_float('alpha', 1e-10, 1, log=True),\n",
        "        \"fit_intercept\": trial.suggest_categorical('fit_intercept', [True, False]),\n",
        "        \"solver\": trial.suggest_categorical('solver', ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'])\n",
        "    }\n",
        "\n",
        "    # Generate a unique identifier for the run\n",
        "    new_uuid = uuid.uuid4()\n",
        "\n",
        "    # Register the model and evaluate its performance\n",
        "    model, metric_eval = register_model_mlflow(f\"Ridge_{new_uuid}\", params, Ridge, X_train, X_test, y_train, y_test)\n",
        "\n",
        "    # Select the metric to be maximized (RMSE)\n",
        "    rmse = metric_eval[\"RMSE\"]\n",
        "\n",
        "    return rmse"
      ],
      "metadata": {
        "id": "lFCvT1QUATOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a study object and optimize the objective function.\n",
        "study = optuna.create_study(direction='minimize') # Minimaize or maximize, depends on the metric\n",
        "study.optimize(objective, n_trials=50) # You have to specify how much trials you want to test"
      ],
      "metadata": {
        "id": "HvPIHNGfATYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "from mlflow.models.signature import infer_signature\n",
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "# Set the MLflow tracking URI\n",
        "mlflow.set_tracking_uri(\"http://localhost:8080\")\n",
        "\n",
        "# Specify the experiment name\n",
        "EXPERIMENT_NAME = \"House Prices\"\n",
        "mlflow.set_experiment(EXPERIMENT_NAME)\n",
        "\n",
        "# Initialize the MLflow client\n",
        "client = MlflowClient()\n",
        "\n",
        "# Name of the model to be used\n",
        "MODEL_NAME = 'tracking-quickstart'\n",
        "\n",
        "# Search for the latest version of the model in the model registry\n",
        "max_version = 0\n",
        "for mv in client.search_model_versions(f\"name='{MODEL_NAME}'\"):\n",
        "    current_stage = dict(mv)['aliases']\n",
        "    if current_stage == ['champion']: # champion is the tag we selected for deploy the model\n",
        "        model_deploy = mv\n",
        "\n",
        "# Download the model\n",
        "model = mlflow.sklearn.load_model(model_deploy.source, dst_path=None)\n",
        "\n",
        "# Use the model\n",
        "model.predict(X_test[:1])"
      ],
      "metadata": {
        "id": "urNflAMNATkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nZgVRei9ATuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E2pVAV9LAT1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ebkU6Nf4AT6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "85FN5QH3AT-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TQG2JUnSAUDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hLE_WLQfAUID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MlXn-fonAULk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "47hJArhYAUOh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}