{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Binary Classifier with TensorFlow in 15 Minutes: Mushroom Classification"
      ],
      "metadata": {
        "id": "RRrEw2sD_m8L"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/fenago/datasets/main/mushrooms.csv'\n",
        "df = pd.read_csv(url)\n",
        "df.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "slTv17Hs_tZZ",
        "outputId": "8b88738c-b7c8-484e-bc64-c89922d7002c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
              "2828     e         x           y         g       t    n               f   \n",
              "487      e         s           f         n       f    n               f   \n",
              "4133     p         x           s         g       f    c               f   \n",
              "165      e         f           y         y       t    l               f   \n",
              "2162     e         f           f         g       t    n               f   \n",
              "\n",
              "     gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
              "2828            c         b          p  ...                        s   \n",
              "487             c         n          p  ...                        s   \n",
              "4133            c         n          g  ...                        s   \n",
              "165             c         b          w  ...                        y   \n",
              "2162            c         b          p  ...                        s   \n",
              "\n",
              "     stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
              "2828                      g                      p         p          w   \n",
              "487                       w                      w         p          w   \n",
              "4133                      w                      w         p          w   \n",
              "165                       w                      w         p          w   \n",
              "2162                      g                      p         p          w   \n",
              "\n",
              "     ring-number ring-type spore-print-color population habitat  \n",
              "2828           o         p                 n          y       d  \n",
              "487            o         p                 n          y       u  \n",
              "4133           o         p                 k          s       d  \n",
              "165            o         p                 n          y       p  \n",
              "2162           o         p                 k          v       d  \n",
              "\n",
              "[5 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b1b8300-2a20-4040-bcd6-49ddfd8f41ab\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>cap-shape</th>\n",
              "      <th>cap-surface</th>\n",
              "      <th>cap-color</th>\n",
              "      <th>bruises</th>\n",
              "      <th>odor</th>\n",
              "      <th>gill-attachment</th>\n",
              "      <th>gill-spacing</th>\n",
              "      <th>gill-size</th>\n",
              "      <th>gill-color</th>\n",
              "      <th>...</th>\n",
              "      <th>stalk-surface-below-ring</th>\n",
              "      <th>stalk-color-above-ring</th>\n",
              "      <th>stalk-color-below-ring</th>\n",
              "      <th>veil-type</th>\n",
              "      <th>veil-color</th>\n",
              "      <th>ring-number</th>\n",
              "      <th>ring-type</th>\n",
              "      <th>spore-print-color</th>\n",
              "      <th>population</th>\n",
              "      <th>habitat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2828</th>\n",
              "      <td>e</td>\n",
              "      <td>x</td>\n",
              "      <td>y</td>\n",
              "      <td>g</td>\n",
              "      <td>t</td>\n",
              "      <td>n</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>b</td>\n",
              "      <td>p</td>\n",
              "      <td>...</td>\n",
              "      <td>s</td>\n",
              "      <td>g</td>\n",
              "      <td>p</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>487</th>\n",
              "      <td>e</td>\n",
              "      <td>s</td>\n",
              "      <td>f</td>\n",
              "      <td>n</td>\n",
              "      <td>f</td>\n",
              "      <td>n</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>n</td>\n",
              "      <td>p</td>\n",
              "      <td>...</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>u</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4133</th>\n",
              "      <td>p</td>\n",
              "      <td>x</td>\n",
              "      <td>s</td>\n",
              "      <td>g</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>n</td>\n",
              "      <td>g</td>\n",
              "      <td>...</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>k</td>\n",
              "      <td>s</td>\n",
              "      <td>d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>e</td>\n",
              "      <td>f</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>t</td>\n",
              "      <td>l</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>b</td>\n",
              "      <td>w</td>\n",
              "      <td>...</td>\n",
              "      <td>y</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2162</th>\n",
              "      <td>e</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>t</td>\n",
              "      <td>n</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>b</td>\n",
              "      <td>p</td>\n",
              "      <td>...</td>\n",
              "      <td>s</td>\n",
              "      <td>g</td>\n",
              "      <td>p</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>k</td>\n",
              "      <td>v</td>\n",
              "      <td>d</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b1b8300-2a20-4040-bcd6-49ddfd8f41ab')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1b1b8300-2a20-4040-bcd6-49ddfd8f41ab button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1b1b8300-2a20-4040-bcd6-49ddfd8f41ab');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-66876e06-f04f-4bde-8d50-cba1aefcec3e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-66876e06-f04f-4bde-8d50-cba1aefcec3e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-66876e06-f04f-4bde-8d50-cba1aefcec3e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_encoded = pd.get_dummies(df, drop_first=True)"
      ],
      "metadata": {
        "id": "FU6ue1p8_v7q"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df_encoded.drop('class_p', axis=1)\n",
        "y = df_encoded['class_p']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "aLEzJPwX_yEx"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics=[\n",
        "        tf.keras.metrics.BinaryAccuracy(name='accuracy')\n",
        "    ]\n",
        ")\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f1gcLFm_0WT",
        "outputId": "4d9a90f1-9c5f-4f53-a452-a740fff2b921"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9190 - loss: 0.2370\n",
            "Epoch 2/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0013\n",
            "Epoch 3/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.0677e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.8299e-05\n",
            "Epoch 5/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.1698e-05\n",
            "Epoch 6/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.5693e-05\n",
            "Epoch 7/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.7321e-05\n",
            "Epoch 8/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2266e-05\n",
            "Epoch 9/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.0537e-06\n",
            "Epoch 10/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.8993e-06\n",
            "Epoch 11/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.3870e-06\n",
            "Epoch 12/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2836e-06\n",
            "Epoch 13/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4596e-06\n",
            "Epoch 14/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8218e-06\n",
            "Epoch 15/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3274e-06\n",
            "Epoch 16/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9286e-06\n",
            "Epoch 17/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6109e-06\n",
            "Epoch 18/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3514e-06\n",
            "Epoch 19/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1399e-06\n",
            "Epoch 20/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6750e-07\n",
            "Epoch 21/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2398e-07\n",
            "Epoch 22/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.0617e-07\n",
            "Epoch 23/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.0686e-07\n",
            "Epoch 24/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.2398e-07\n",
            "Epoch 25/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.5379e-07\n",
            "Epoch 26/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9375e-07\n",
            "Epoch 27/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4315e-07\n",
            "Epoch 28/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9946e-07\n",
            "Epoch 29/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.6182e-07\n",
            "Epoch 30/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.2928e-07\n",
            "Epoch 31/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0150e-07\n",
            "Epoch 32/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.7713e-07\n",
            "Epoch 33/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5589e-07\n",
            "Epoch 34/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3739e-07\n",
            "Epoch 35/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2114e-07\n",
            "Epoch 36/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0698e-07\n",
            "Epoch 37/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.4586e-08\n",
            "Epoch 38/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.3751e-08\n",
            "Epoch 39/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.4224e-08\n",
            "Epoch 40/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.5881e-08\n",
            "Epoch 41/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.8506e-08\n",
            "Epoch 42/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.2012e-08\n",
            "Epoch 43/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6319e-08\n",
            "Epoch 44/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.1262e-08\n",
            "Epoch 45/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.6842e-08\n",
            "Epoch 46/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2893e-08\n",
            "Epoch 47/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9442e-08\n",
            "Epoch 48/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6344e-08\n",
            "Epoch 49/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3632e-08\n",
            "Epoch 50/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1208e-08\n",
            "Epoch 51/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9053e-08\n",
            "Epoch 52/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7130e-08\n",
            "Epoch 53/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5419e-08\n",
            "Epoch 54/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3910e-08\n",
            "Epoch 55/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2540e-08\n",
            "Epoch 56/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1333e-08\n",
            "Epoch 57/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.0231e-08\n",
            "Epoch 58/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.2628e-09\n",
            "Epoch 59/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 8.4067e-09\n",
            "Epoch 60/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.6299e-09\n",
            "Epoch 61/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.9092e-09\n",
            "Epoch 62/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2879e-09\n",
            "Epoch 63/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7277e-09\n",
            "Epoch 64/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2216e-09\n",
            "Epoch 65/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7690e-09\n",
            "Epoch 66/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3755e-09\n",
            "Epoch 67/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0176e-09\n",
            "Epoch 68/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7007e-09\n",
            "Epoch 69/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3940e-09\n",
            "Epoch 70/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1293e-09\n",
            "Epoch 71/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8902e-09\n",
            "Epoch 72/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6636e-09\n",
            "Epoch 73/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4508e-09\n",
            "Epoch 74/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2816e-09\n",
            "Epoch 75/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1235e-09\n",
            "Epoch 76/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9737e-09\n",
            "Epoch 77/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8287e-09\n",
            "Epoch 78/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.7088e-09\n",
            "Epoch 79/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6007e-09\n",
            "Epoch 80/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.4979e-09\n",
            "Epoch 81/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4082e-09\n",
            "Epoch 82/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.3206e-09\n",
            "Epoch 83/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.2367e-09\n",
            "Epoch 84/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1723e-09\n",
            "Epoch 85/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0980e-09\n",
            "Epoch 86/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0480e-09\n",
            "Epoch 87/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.9692e-10\n",
            "Epoch 88/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.5715e-10\n",
            "Epoch 89/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.0019e-10\n",
            "Epoch 90/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 8.7309e-10\n",
            "Epoch 91/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 8.4851e-10\n",
            "Epoch 92/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.1766e-10\n",
            "Epoch 93/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.8449e-10\n",
            "Epoch 94/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.5420e-10\n",
            "Epoch 95/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.1688e-10\n",
            "Epoch 96/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.8140e-10\n",
            "Epoch 97/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6906e-10\n",
            "Epoch 98/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5044e-10\n",
            "Epoch 99/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2544e-10\n",
            "Epoch 100/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.9540e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4_OA7Jp_25_",
        "outputId": "527d22e4-e641-4f48-bcb6-9e07f80265be"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_classes_class = [\n",
        "    'p' if prob > 0.5 else 'e' for prob in np.ravel(predictions)\n",
        "]\n",
        "# convert prediction probabilities to binary predictions\n",
        "prediction_classes = [\n",
        "    1 if prob > 0.5 else 0 for prob in np.ravel(predictions)\n",
        "]\n",
        "\n",
        "prediction_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW5N_YmUAXTB",
        "outputId": "e67e8456-475a-4d8f-805d-3625f436b70d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print(confusion_matrix(y_test, prediction_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHL7YQEeAZrI",
        "outputId": "e3e598ea-796e-4788-f6f4-95c9338e0537"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[843   0]\n",
            " [  0 782]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(f'Accuracy: {accuracy_score(y_test, prediction_classes):.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwzOMmAtAcA1",
        "outputId": "a94fbbf9-d206-48e0-ca28-b7c28990561b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KHBAJGikAg3K"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change learning rate\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), # decreasing learning rate\n",
        "    metrics=[\n",
        "        tf.keras.metrics.BinaryAccuracy(name='accuracy')\n",
        "    ]\n",
        ")\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3AW1dYhAgzz",
        "outputId": "1fcb6425-c0a9-48b3-acd4-90d32a2cb482"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7554 - loss: 0.5916\n",
            "Epoch 2/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9510 - loss: 0.1602\n",
            "Epoch 3/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9838 - loss: 0.0485\n",
            "Epoch 4/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9959 - loss: 0.0194\n",
            "Epoch 5/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0100\n",
            "Epoch 6/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0056\n",
            "Epoch 7/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0034\n",
            "Epoch 8/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0022\n",
            "Epoch 9/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0015\n",
            "Epoch 10/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0011\n",
            "Epoch 11/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.9842e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0677e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7159e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7298e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9944e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4349e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0002e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6555e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.3810e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1598e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.8019e-05\n",
            "Epoch 22/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.3111e-05\n",
            "Epoch 23/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.0775e-05\n",
            "Epoch 24/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.0505e-05\n",
            "Epoch 25/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.1914e-05\n",
            "Epoch 26/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.4692e-05\n",
            "Epoch 27/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8556e-05\n",
            "Epoch 28/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.3344e-05\n",
            "Epoch 29/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.8917e-05\n",
            "Epoch 30/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.5124e-05\n",
            "Epoch 31/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1867e-05\n",
            "Epoch 32/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9057e-05\n",
            "Epoch 33/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6634e-05\n",
            "Epoch 34/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.4540e-05\n",
            "Epoch 35/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.2709e-05\n",
            "Epoch 36/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.1120e-05\n",
            "Epoch 37/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.7454e-06\n",
            "Epoch 38/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.5488e-06\n",
            "Epoch 39/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.5020e-06\n",
            "Epoch 40/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.5901e-06\n",
            "Epoch 41/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.7934e-06\n",
            "Epoch 42/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.0944e-06\n",
            "Epoch 43/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.4835e-06\n",
            "Epoch 44/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 3.9498e-06\n",
            "Epoch 45/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.4796e-06\n",
            "Epoch 46/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.0690e-06\n",
            "Epoch 47/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.7092e-06\n",
            "Epoch 48/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3937e-06\n",
            "Epoch 49/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1158e-06\n",
            "Epoch 50/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8715e-06\n",
            "Epoch 51/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6559e-06\n",
            "Epoch 52/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4654e-06\n",
            "Epoch 53/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2975e-06\n",
            "Epoch 54/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1500e-06\n",
            "Epoch 55/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0198e-06\n",
            "Epoch 56/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.0485e-07\n",
            "Epoch 57/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.0306e-07\n",
            "Epoch 58/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.1350e-07\n",
            "Epoch 59/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.3399e-07\n",
            "Epoch 60/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.6352e-07\n",
            "Epoch 61/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0138e-07\n",
            "Epoch 62/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4635e-07\n",
            "Epoch 63/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9765e-07\n",
            "Epoch 64/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5451e-07\n",
            "Epoch 65/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1620e-07\n",
            "Epoch 66/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8209e-07\n",
            "Epoch 67/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5191e-07\n",
            "Epoch 68/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2516e-07\n",
            "Epoch 69/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0129e-07\n",
            "Epoch 70/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8012e-07\n",
            "Epoch 71/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6128e-07\n",
            "Epoch 72/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4457e-07\n",
            "Epoch 73/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2955e-07\n",
            "Epoch 74/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1621e-07\n",
            "Epoch 75/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0435e-07\n",
            "Epoch 76/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.3785e-08\n",
            "Epoch 77/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.4395e-08\n",
            "Epoch 78/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 7.5999e-08\n",
            "Epoch 79/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 6.8513e-08\n",
            "Epoch 80/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 6.1809e-08\n",
            "Epoch 81/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5852e-08\n",
            "Epoch 82/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0541e-08\n",
            "Epoch 83/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5782e-08\n",
            "Epoch 84/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1496e-08\n",
            "Epoch 85/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7647e-08\n",
            "Epoch 86/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4215e-08\n",
            "Epoch 87/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1121e-08\n",
            "Epoch 88/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8334e-08\n",
            "Epoch 89/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5823e-08\n",
            "Epoch 90/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3535e-08\n",
            "Epoch 91/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1495e-08\n",
            "Epoch 92/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9644e-08\n",
            "Epoch 93/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7972e-08\n",
            "Epoch 94/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6467e-08\n",
            "Epoch 95/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.5106e-08\n",
            "Epoch 96/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.3885e-08\n",
            "Epoch 97/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2767e-08\n",
            "Epoch 98/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.1761e-08\n",
            "Epoch 99/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0849e-08\n",
            "Epoch 100/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0021e-08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add addition layer\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'), # adding another layer\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics=[\n",
        "        tf.keras.metrics.BinaryAccuracy(name='accuracy')\n",
        "    ]\n",
        ")\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAZGkAT4AgvM",
        "outputId": "5b223b70-26c7-4916-a973-d2c6e6622f4a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9428 - loss: 0.1915\n",
            "Epoch 2/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.5721e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.8535e-05\n",
            "Epoch 4/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.7041e-05\n",
            "Epoch 5/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.3450e-05\n",
            "Epoch 6/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 7.6989e-06\n",
            "Epoch 7/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.8579e-06\n",
            "Epoch 8/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2951e-06\n",
            "Epoch 9/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3526e-06\n",
            "Epoch 10/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7468e-06\n",
            "Epoch 11/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3350e-06\n",
            "Epoch 12/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0441e-06\n",
            "Epoch 13/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.3299e-07\n",
            "Epoch 14/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7416e-07\n",
            "Epoch 15/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.5253e-07\n",
            "Epoch 16/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5779e-07\n",
            "Epoch 17/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8259e-07\n",
            "Epoch 18/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2233e-07\n",
            "Epoch 19/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7340e-07\n",
            "Epoch 20/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.3320e-07\n",
            "Epoch 21/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9996e-07\n",
            "Epoch 22/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7221e-07\n",
            "Epoch 23/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.4892e-07\n",
            "Epoch 24/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.2930e-07\n",
            "Epoch 25/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.1258e-07\n",
            "Epoch 26/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.8308e-08\n",
            "Epoch 27/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.6059e-08\n",
            "Epoch 28/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.5570e-08\n",
            "Epoch 29/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.6484e-08\n",
            "Epoch 30/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.8588e-08\n",
            "Epoch 31/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.1709e-08\n",
            "Epoch 32/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.5717e-08\n",
            "Epoch 33/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.0508e-08\n",
            "Epoch 34/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.5932e-08\n",
            "Epoch 35/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1932e-08\n",
            "Epoch 36/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.8418e-08\n",
            "Epoch 37/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.5329e-08\n",
            "Epoch 38/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2622e-08\n",
            "Epoch 39/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.0225e-08\n",
            "Epoch 40/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8121e-08\n",
            "Epoch 41/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6262e-08\n",
            "Epoch 42/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.4624e-08\n",
            "Epoch 43/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3172e-08\n",
            "Epoch 44/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1856e-08\n",
            "Epoch 45/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0699e-08\n",
            "Epoch 46/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.6640e-09\n",
            "Epoch 47/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.7396e-09\n",
            "Epoch 48/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.9148e-09\n",
            "Epoch 49/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1806e-09\n",
            "Epoch 50/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5249e-09\n",
            "Epoch 51/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.9383e-09\n",
            "Epoch 52/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4161e-09\n",
            "Epoch 53/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9476e-09\n",
            "Epoch 54/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.5259e-09\n",
            "Epoch 55/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.1380e-09\n",
            "Epoch 56/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.7912e-09\n",
            "Epoch 57/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4807e-09\n",
            "Epoch 58/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.2104e-09\n",
            "Epoch 59/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.9587e-09\n",
            "Epoch 60/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.7268e-09\n",
            "Epoch 61/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.5162e-09\n",
            "Epoch 62/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.3254e-09\n",
            "Epoch 63/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.1528e-09\n",
            "Epoch 64/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9961e-09\n",
            "Epoch 65/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8571e-09\n",
            "Epoch 66/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.7278e-09\n",
            "Epoch 67/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6061e-09\n",
            "Epoch 68/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.4963e-09\n",
            "Epoch 69/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.3915e-09\n",
            "Epoch 70/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.2995e-09\n",
            "Epoch 71/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.2132e-09\n",
            "Epoch 72/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.1309e-09\n",
            "Epoch 73/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.0583e-09\n",
            "Epoch 74/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 9.8709e-10\n",
            "Epoch 75/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.2133e-10\n",
            "Epoch 76/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.5957e-10\n",
            "Epoch 77/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.0327e-10\n",
            "Epoch 78/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5291e-10\n",
            "Epoch 79/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.1045e-10\n",
            "Epoch 80/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.6749e-10\n",
            "Epoch 81/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.3086e-10\n",
            "Epoch 82/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.9405e-10\n",
            "Epoch 83/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.6438e-10\n",
            "Epoch 84/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.3288e-10\n",
            "Epoch 85/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.0247e-10\n",
            "Epoch 86/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.7571e-10\n",
            "Epoch 87/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.4995e-10\n",
            "Epoch 88/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.2678e-10\n",
            "Epoch 89/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.0420e-10\n",
            "Epoch 90/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.8594e-10\n",
            "Epoch 91/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.6570e-10\n",
            "Epoch 92/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.4875e-10\n",
            "Epoch 93/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.3145e-10\n",
            "Epoch 94/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.1836e-10\n",
            "Epoch 95/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.0371e-10\n",
            "Epoch 96/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.9266e-10\n",
            "Epoch 97/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.8515e-10\n",
            "Epoch 98/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.7064e-10\n",
            "Epoch 99/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.5978e-10\n",
            "Epoch 100/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.5533e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# L1 Regularization\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "model_l1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l1(0.001)),\n",
        "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l1(0.001)),\n",
        "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l1(0.001)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_l1.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics=[\n",
        "        tf.keras.metrics.BinaryAccuracy(name='accuracy')\n",
        "    ]\n",
        ")\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    verbose=1,\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history_l1 = model_l1.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=100,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[early_stop]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPWmCIyWAgsF",
        "outputId": "aefd3a9d-03f0-41f1-e49d-090085311601"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9055 - loss: 2.0084 - val_accuracy: 0.9988 - val_loss: 0.4264\n",
            "Epoch 2/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.3473 - val_accuracy: 0.9988 - val_loss: 0.2124\n",
            "Epoch 3/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9984 - loss: 0.1935 - val_accuracy: 0.9994 - val_loss: 0.1442\n",
            "Epoch 4/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9986 - loss: 0.1357 - val_accuracy: 0.9994 - val_loss: 0.1083\n",
            "Epoch 5/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9987 - loss: 0.1039 - val_accuracy: 0.9994 - val_loss: 0.0870\n",
            "Epoch 6/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9987 - loss: 0.0844 - val_accuracy: 0.9994 - val_loss: 0.0728\n",
            "Epoch 7/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9990 - loss: 0.0710 - val_accuracy: 0.9994 - val_loss: 0.0625\n",
            "Epoch 8/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0613 - val_accuracy: 1.0000 - val_loss: 0.0552\n",
            "Epoch 9/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9990 - loss: 0.0544 - val_accuracy: 1.0000 - val_loss: 0.0499\n",
            "Epoch 10/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0492 - val_accuracy: 1.0000 - val_loss: 0.0455\n",
            "Epoch 11/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0449 - val_accuracy: 1.0000 - val_loss: 0.0417\n",
            "Epoch 12/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0411 - val_accuracy: 1.0000 - val_loss: 0.0383\n",
            "Epoch 13/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0379 - val_accuracy: 1.0000 - val_loss: 0.0355\n",
            "Epoch 14/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0351 - val_accuracy: 1.0000 - val_loss: 0.0328\n",
            "Epoch 15/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0325 - val_accuracy: 1.0000 - val_loss: 0.0302\n",
            "Epoch 16/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0299 - val_accuracy: 1.0000 - val_loss: 0.0278\n",
            "Epoch 17/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0275 - val_accuracy: 1.0000 - val_loss: 0.0256\n",
            "Epoch 18/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0254 - val_accuracy: 1.0000 - val_loss: 0.0237\n",
            "Epoch 19/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0237 - val_accuracy: 1.0000 - val_loss: 0.0224\n",
            "Epoch 20/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0225 - val_accuracy: 1.0000 - val_loss: 0.0215\n",
            "Epoch 21/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0216 - val_accuracy: 1.0000 - val_loss: 0.0207\n",
            "Epoch 22/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0209 - val_accuracy: 1.0000 - val_loss: 0.0201\n",
            "Epoch 23/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0203 - val_accuracy: 1.0000 - val_loss: 0.0197\n",
            "Epoch 24/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0199 - val_accuracy: 1.0000 - val_loss: 0.0193\n",
            "Epoch 25/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0195 - val_accuracy: 1.0000 - val_loss: 0.0189\n",
            "Epoch 26/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0191 - val_accuracy: 1.0000 - val_loss: 0.0185\n",
            "Epoch 27/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0187 - val_accuracy: 1.0000 - val_loss: 0.0181\n",
            "Epoch 28/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0182 - val_accuracy: 1.0000 - val_loss: 0.0176\n",
            "Epoch 29/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0178 - val_accuracy: 1.0000 - val_loss: 0.0173\n",
            "Epoch 30/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0175 - val_accuracy: 1.0000 - val_loss: 0.0170\n",
            "Epoch 31/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0172 - val_accuracy: 1.0000 - val_loss: 0.0168\n",
            "Epoch 32/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0170 - val_accuracy: 1.0000 - val_loss: 0.0166\n",
            "Epoch 33/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0168 - val_accuracy: 1.0000 - val_loss: 0.0164\n",
            "Epoch 34/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0166 - val_accuracy: 1.0000 - val_loss: 0.0163\n",
            "Epoch 35/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0164 - val_accuracy: 1.0000 - val_loss: 0.0161\n",
            "Epoch 36/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0162 - val_accuracy: 1.0000 - val_loss: 0.0160\n",
            "Epoch 37/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0161 - val_accuracy: 1.0000 - val_loss: 0.0159\n",
            "Epoch 38/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0160 - val_accuracy: 1.0000 - val_loss: 0.0158\n",
            "Epoch 39/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0159 - val_accuracy: 1.0000 - val_loss: 0.0157\n",
            "Epoch 40/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0158 - val_accuracy: 1.0000 - val_loss: 0.0156\n",
            "Epoch 41/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0157 - val_accuracy: 1.0000 - val_loss: 0.0155\n",
            "Epoch 42/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0156 - val_accuracy: 1.0000 - val_loss: 0.0154\n",
            "Epoch 43/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0156 - val_accuracy: 1.0000 - val_loss: 0.0153\n",
            "Epoch 44/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0155 - val_accuracy: 1.0000 - val_loss: 0.0152\n",
            "Epoch 45/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0154 - val_accuracy: 1.0000 - val_loss: 0.0152\n",
            "Epoch 46/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0153 - val_accuracy: 1.0000 - val_loss: 0.0151\n",
            "Epoch 47/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0153 - val_accuracy: 1.0000 - val_loss: 0.0150\n",
            "Epoch 48/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0152 - val_accuracy: 1.0000 - val_loss: 0.0150\n",
            "Epoch 49/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0151 - val_accuracy: 1.0000 - val_loss: 0.0149\n",
            "Epoch 50/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0151 - val_accuracy: 1.0000 - val_loss: 0.0149\n",
            "Epoch 51/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0150 - val_accuracy: 1.0000 - val_loss: 0.0148\n",
            "Epoch 52/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0149 - val_accuracy: 1.0000 - val_loss: 0.0147\n",
            "Epoch 53/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0149 - val_accuracy: 1.0000 - val_loss: 0.0147\n",
            "Epoch 54/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0148 - val_accuracy: 1.0000 - val_loss: 0.0146\n",
            "Epoch 55/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0148 - val_accuracy: 1.0000 - val_loss: 0.0146\n",
            "Epoch 56/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0147 - val_accuracy: 1.0000 - val_loss: 0.0145\n",
            "Epoch 57/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0146 - val_accuracy: 1.0000 - val_loss: 0.0144\n",
            "Epoch 58/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0146 - val_accuracy: 1.0000 - val_loss: 0.0144\n",
            "Epoch 59/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0145 - val_accuracy: 1.0000 - val_loss: 0.0143\n",
            "Epoch 60/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0145 - val_accuracy: 1.0000 - val_loss: 0.0143\n",
            "Epoch 61/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0144 - val_accuracy: 1.0000 - val_loss: 0.0142\n",
            "Epoch 62/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0144 - val_accuracy: 1.0000 - val_loss: 0.0142\n",
            "Epoch 63/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0143 - val_accuracy: 1.0000 - val_loss: 0.0141\n",
            "Epoch 64/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0143 - val_accuracy: 1.0000 - val_loss: 0.0141\n",
            "Epoch 65/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0142 - val_accuracy: 1.0000 - val_loss: 0.0141\n",
            "Epoch 66/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0142 - val_accuracy: 1.0000 - val_loss: 0.0140\n",
            "Epoch 67/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0141 - val_accuracy: 1.0000 - val_loss: 0.0139\n",
            "Epoch 68/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0141 - val_accuracy: 1.0000 - val_loss: 0.0139\n",
            "Epoch 69/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0141 - val_accuracy: 1.0000 - val_loss: 0.0139\n",
            "Epoch 70/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0140 - val_accuracy: 1.0000 - val_loss: 0.0138\n",
            "Epoch 71/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0140 - val_accuracy: 1.0000 - val_loss: 0.0137\n",
            "Epoch 72/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0139 - val_accuracy: 1.0000 - val_loss: 0.0137\n",
            "Epoch 73/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0139 - val_accuracy: 1.0000 - val_loss: 0.0137\n",
            "Epoch 74/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0138 - val_accuracy: 1.0000 - val_loss: 0.0137\n",
            "Epoch 75/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0138 - val_accuracy: 1.0000 - val_loss: 0.0136\n",
            "Epoch 76/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0138 - val_accuracy: 1.0000 - val_loss: 0.0136\n",
            "Epoch 77/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0137 - val_accuracy: 1.0000 - val_loss: 0.0135\n",
            "Epoch 78/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0137 - val_accuracy: 1.0000 - val_loss: 0.0135\n",
            "Epoch 79/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0136 - val_accuracy: 1.0000 - val_loss: 0.0135\n",
            "Epoch 80/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0136 - val_accuracy: 1.0000 - val_loss: 0.0134\n",
            "Epoch 81/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0136 - val_accuracy: 1.0000 - val_loss: 0.0134\n",
            "Epoch 82/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0135 - val_accuracy: 1.0000 - val_loss: 0.0133\n",
            "Epoch 83/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0135 - val_accuracy: 1.0000 - val_loss: 0.0133\n",
            "Epoch 84/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0135 - val_accuracy: 1.0000 - val_loss: 0.0133\n",
            "Epoch 85/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0134 - val_accuracy: 1.0000 - val_loss: 0.0133\n",
            "Epoch 86/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0134 - val_accuracy: 1.0000 - val_loss: 0.0132\n",
            "Epoch 87/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0134 - val_accuracy: 1.0000 - val_loss: 0.0132\n",
            "Epoch 88/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0133 - val_accuracy: 1.0000 - val_loss: 0.0131\n",
            "Epoch 89/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0133 - val_accuracy: 1.0000 - val_loss: 0.0131\n",
            "Epoch 90/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0132 - val_accuracy: 1.0000 - val_loss: 0.0131\n",
            "Epoch 91/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0132 - val_accuracy: 1.0000 - val_loss: 0.0130\n",
            "Epoch 92/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0132 - val_accuracy: 1.0000 - val_loss: 0.0130\n",
            "Epoch 93/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 1.0000 - val_loss: 0.0130\n",
            "Epoch 94/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 1.0000 - val_loss: 0.0130\n",
            "Epoch 95/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 1.0000 - val_loss: 0.0129\n",
            "Epoch 96/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 1.0000 - val_loss: 0.0129\n",
            "Epoch 97/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 1.0000 - val_loss: 0.0129\n",
            "Epoch 98/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 1.0000 - val_loss: 0.0128\n",
            "Epoch 99/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 1.0000 - val_loss: 0.0128\n",
            "Epoch 100/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0129 - val_accuracy: 1.0000 - val_loss: 0.0128\n",
            "Restoring model weights from the end of the best epoch: 100.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stop early\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l1(0.001)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l1(0.001)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l1(0.001)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics=[\n",
        "        tf.keras.metrics.BinaryAccuracy(name='accuracy')\n",
        "    ]\n",
        ")\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    verbose=1,\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), callbacks=[early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHMOD3vBAgdx",
        "outputId": "39b2c82d-04ee-4985-e83c-8ad1f053634c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7837 - loss: 2.3901 - val_accuracy: 0.9858 - val_loss: 0.8176\n",
            "Epoch 2/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9796 - loss: 0.6960 - val_accuracy: 0.9957 - val_loss: 0.3744\n",
            "Epoch 3/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9877 - loss: 0.3657 - val_accuracy: 0.9988 - val_loss: 0.2559\n",
            "Epoch 4/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9899 - loss: 0.2753 - val_accuracy: 0.9988 - val_loss: 0.2061\n",
            "Epoch 5/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9933 - loss: 0.2246 - val_accuracy: 0.9988 - val_loss: 0.1789\n",
            "Epoch 6/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9932 - loss: 0.1971 - val_accuracy: 0.9988 - val_loss: 0.1607\n",
            "Epoch 7/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9936 - loss: 0.1821 - val_accuracy: 0.9994 - val_loss: 0.1467\n",
            "Epoch 8/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9933 - loss: 0.1679 - val_accuracy: 0.9994 - val_loss: 0.1380\n",
            "Epoch 9/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9942 - loss: 0.1563 - val_accuracy: 0.9994 - val_loss: 0.1283\n",
            "Epoch 10/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9962 - loss: 0.1450 - val_accuracy: 0.9994 - val_loss: 0.1206\n",
            "Epoch 11/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9952 - loss: 0.1407 - val_accuracy: 0.9994 - val_loss: 0.1156\n",
            "Epoch 12/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9937 - loss: 0.1360 - val_accuracy: 0.9994 - val_loss: 0.1112\n",
            "Epoch 13/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9945 - loss: 0.1318 - val_accuracy: 0.9994 - val_loss: 0.1066\n",
            "Epoch 14/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9960 - loss: 0.1243 - val_accuracy: 0.9994 - val_loss: 0.1059\n",
            "Epoch 15/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9959 - loss: 0.1212 - val_accuracy: 0.9994 - val_loss: 0.1063\n",
            "Epoch 16/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9931 - loss: 0.1229 - val_accuracy: 0.9994 - val_loss: 0.1015\n",
            "Epoch 17/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9950 - loss: 0.1171 - val_accuracy: 0.9994 - val_loss: 0.0983\n",
            "Epoch 18/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9955 - loss: 0.1165 - val_accuracy: 0.9994 - val_loss: 0.0952\n",
            "Epoch 19/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9937 - loss: 0.1158 - val_accuracy: 1.0000 - val_loss: 0.0948\n",
            "Epoch 20/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9927 - loss: 0.1174 - val_accuracy: 1.0000 - val_loss: 0.0938\n",
            "Epoch 21/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9943 - loss: 0.1126 - val_accuracy: 1.0000 - val_loss: 0.0950\n",
            "Epoch 22/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9956 - loss: 0.1097 - val_accuracy: 1.0000 - val_loss: 0.0913\n",
            "Epoch 23/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9951 - loss: 0.1052 - val_accuracy: 1.0000 - val_loss: 0.0886\n",
            "Epoch 24/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.1072 - val_accuracy: 1.0000 - val_loss: 0.0869\n",
            "Epoch 25/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9941 - loss: 0.1031 - val_accuracy: 1.0000 - val_loss: 0.0871\n",
            "Epoch 26/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.1065 - val_accuracy: 1.0000 - val_loss: 0.0860\n",
            "Epoch 27/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9941 - loss: 0.1024 - val_accuracy: 1.0000 - val_loss: 0.0826\n",
            "Epoch 28/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9947 - loss: 0.1019 - val_accuracy: 1.0000 - val_loss: 0.0824\n",
            "Epoch 29/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9947 - loss: 0.0998 - val_accuracy: 1.0000 - val_loss: 0.0807\n",
            "Epoch 30/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9943 - loss: 0.0974 - val_accuracy: 1.0000 - val_loss: 0.0830\n",
            "Epoch 31/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 0.1020 - val_accuracy: 1.0000 - val_loss: 0.0818\n",
            "Epoch 32/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9941 - loss: 0.0988 - val_accuracy: 1.0000 - val_loss: 0.0813\n",
            "Epoch 33/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.0938 - val_accuracy: 1.0000 - val_loss: 0.0786\n",
            "Epoch 34/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0902 - val_accuracy: 1.0000 - val_loss: 0.0783\n",
            "Epoch 35/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0888 - val_accuracy: 1.0000 - val_loss: 0.0763\n",
            "Epoch 36/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9959 - loss: 0.0873 - val_accuracy: 1.0000 - val_loss: 0.0734\n",
            "Epoch 37/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9937 - loss: 0.0951 - val_accuracy: 1.0000 - val_loss: 0.0745\n",
            "Epoch 38/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9956 - loss: 0.0859 - val_accuracy: 1.0000 - val_loss: 0.0710\n",
            "Epoch 39/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9950 - loss: 0.0865 - val_accuracy: 1.0000 - val_loss: 0.0702\n",
            "Epoch 40/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9949 - loss: 0.0845 - val_accuracy: 1.0000 - val_loss: 0.0714\n",
            "Epoch 41/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9957 - loss: 0.0840 - val_accuracy: 1.0000 - val_loss: 0.0718\n",
            "Epoch 42/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9959 - loss: 0.0851 - val_accuracy: 1.0000 - val_loss: 0.0697\n",
            "Epoch 43/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9943 - loss: 0.0830 - val_accuracy: 1.0000 - val_loss: 0.0704\n",
            "Epoch 44/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9972 - loss: 0.0823 - val_accuracy: 1.0000 - val_loss: 0.0674\n",
            "Epoch 45/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9953 - loss: 0.0809 - val_accuracy: 1.0000 - val_loss: 0.0729\n",
            "Epoch 46/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9962 - loss: 0.0814 - val_accuracy: 1.0000 - val_loss: 0.0688\n",
            "Epoch 47/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9957 - loss: 0.0788 - val_accuracy: 1.0000 - val_loss: 0.0701\n",
            "Epoch 48/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0820 - val_accuracy: 1.0000 - val_loss: 0.0679\n",
            "Epoch 49/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9944 - loss: 0.0866 - val_accuracy: 0.9994 - val_loss: 0.0737\n",
            "Epoch 50/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9959 - loss: 0.0834 - val_accuracy: 1.0000 - val_loss: 0.0700\n",
            "Epoch 51/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9963 - loss: 0.0851 - val_accuracy: 1.0000 - val_loss: 0.0653\n",
            "Epoch 52/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9936 - loss: 0.0848 - val_accuracy: 1.0000 - val_loss: 0.0680\n",
            "Epoch 53/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9941 - loss: 0.0819 - val_accuracy: 1.0000 - val_loss: 0.0651\n",
            "Epoch 54/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9951 - loss: 0.0806 - val_accuracy: 1.0000 - val_loss: 0.0683\n",
            "Epoch 55/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9964 - loss: 0.0792 - val_accuracy: 1.0000 - val_loss: 0.0676\n",
            "Epoch 56/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9948 - loss: 0.0858 - val_accuracy: 1.0000 - val_loss: 0.0648\n",
            "Epoch 57/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9946 - loss: 0.0821 - val_accuracy: 1.0000 - val_loss: 0.0664\n",
            "Epoch 58/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9959 - loss: 0.0778 - val_accuracy: 1.0000 - val_loss: 0.0646\n",
            "Epoch 59/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9942 - loss: 0.0828 - val_accuracy: 1.0000 - val_loss: 0.0689\n",
            "Epoch 60/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9950 - loss: 0.0839 - val_accuracy: 1.0000 - val_loss: 0.0664\n",
            "Epoch 61/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0786 - val_accuracy: 1.0000 - val_loss: 0.0650\n",
            "Epoch 62/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9935 - loss: 0.0830 - val_accuracy: 1.0000 - val_loss: 0.0637\n",
            "Epoch 63/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9937 - loss: 0.0803 - val_accuracy: 1.0000 - val_loss: 0.0675\n",
            "Epoch 64/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9950 - loss: 0.0818 - val_accuracy: 1.0000 - val_loss: 0.0641\n",
            "Epoch 65/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9936 - loss: 0.0843 - val_accuracy: 1.0000 - val_loss: 0.0674\n",
            "Epoch 66/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9971 - loss: 0.0789 - val_accuracy: 1.0000 - val_loss: 0.0631\n",
            "Epoch 67/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9970 - loss: 0.0717 - val_accuracy: 1.0000 - val_loss: 0.0644\n",
            "Epoch 68/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9964 - loss: 0.0782 - val_accuracy: 1.0000 - val_loss: 0.0630\n",
            "Epoch 69/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9938 - loss: 0.0846 - val_accuracy: 1.0000 - val_loss: 0.0631\n",
            "Epoch 70/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0777 - val_accuracy: 1.0000 - val_loss: 0.0655\n",
            "Epoch 71/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9956 - loss: 0.0782 - val_accuracy: 1.0000 - val_loss: 0.0642\n",
            "Epoch 72/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9941 - loss: 0.0847 - val_accuracy: 1.0000 - val_loss: 0.0632\n",
            "Epoch 73/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9944 - loss: 0.0805 - val_accuracy: 1.0000 - val_loss: 0.0626\n",
            "Epoch 74/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9970 - loss: 0.0713 - val_accuracy: 1.0000 - val_loss: 0.0638\n",
            "Epoch 75/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9962 - loss: 0.0762 - val_accuracy: 1.0000 - val_loss: 0.0652\n",
            "Epoch 76/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9936 - loss: 0.0840 - val_accuracy: 1.0000 - val_loss: 0.0641\n",
            "Epoch 77/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9953 - loss: 0.0763 - val_accuracy: 1.0000 - val_loss: 0.0636\n",
            "Epoch 78/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9942 - loss: 0.0822 - val_accuracy: 1.0000 - val_loss: 0.0629\n",
            "Epoch 79/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9954 - loss: 0.0766 - val_accuracy: 1.0000 - val_loss: 0.0599\n",
            "Epoch 80/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0702 - val_accuracy: 1.0000 - val_loss: 0.0624\n",
            "Epoch 81/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0757 - val_accuracy: 1.0000 - val_loss: 0.0644\n",
            "Epoch 82/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9956 - loss: 0.0781 - val_accuracy: 1.0000 - val_loss: 0.0611\n",
            "Epoch 83/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0817 - val_accuracy: 1.0000 - val_loss: 0.0609\n",
            "Epoch 84/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9940 - loss: 0.0797 - val_accuracy: 1.0000 - val_loss: 0.0605\n",
            "Epoch 85/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9965 - loss: 0.0720 - val_accuracy: 1.0000 - val_loss: 0.0604\n",
            "Epoch 86/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9950 - loss: 0.0761 - val_accuracy: 1.0000 - val_loss: 0.0626\n",
            "Epoch 87/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9955 - loss: 0.0781 - val_accuracy: 1.0000 - val_loss: 0.0629\n",
            "Epoch 88/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9968 - loss: 0.0713 - val_accuracy: 1.0000 - val_loss: 0.0598\n",
            "Epoch 89/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9955 - loss: 0.0783 - val_accuracy: 1.0000 - val_loss: 0.0619\n",
            "Epoch 90/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9959 - loss: 0.0780 - val_accuracy: 1.0000 - val_loss: 0.0599\n",
            "Epoch 91/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9954 - loss: 0.0757 - val_accuracy: 1.0000 - val_loss: 0.0645\n",
            "Epoch 92/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9954 - loss: 0.0781 - val_accuracy: 1.0000 - val_loss: 0.0615\n",
            "Epoch 93/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9959 - loss: 0.0753 - val_accuracy: 1.0000 - val_loss: 0.0617\n",
            "Epoch 94/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0762 - val_accuracy: 1.0000 - val_loss: 0.0599\n",
            "Epoch 95/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9942 - loss: 0.0802 - val_accuracy: 1.0000 - val_loss: 0.0603\n",
            "Epoch 96/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9955 - loss: 0.0707 - val_accuracy: 1.0000 - val_loss: 0.0612\n",
            "Epoch 97/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0745 - val_accuracy: 1.0000 - val_loss: 0.0579\n",
            "Epoch 98/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0750 - val_accuracy: 1.0000 - val_loss: 0.0597\n",
            "Epoch 99/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9947 - loss: 0.0759 - val_accuracy: 1.0000 - val_loss: 0.0628\n",
            "Epoch 100/100\n",
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9961 - loss: 0.0758 - val_accuracy: 1.0000 - val_loss: 0.0591\n",
            "Restoring model weights from the end of the best epoch: 97.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'val'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "GbM16dMTBZV5",
        "outputId": "610b73b2-238d-4628-a0c9-39a904f9f839"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGWHrqiqDq9c",
        "outputId": "74b9b2f0-a867-436b-90e1-616bc1876703"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('mushroom_classification_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhqXhIyiBZQk",
        "outputId": "85dae85b-bc05-435e-cfe3-aa5807fc1109"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "loaded_model = load_model('mushroom_classification_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U65raNUeBg1g",
        "outputId": "b99a7a61-9c8d-4afd-b712-9d7f13a14dba"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_data = pd.DataFrame({\n",
        "    'cap-shape': ['f'],\n",
        "    'cap-surface': ['y'],\n",
        "    'cap-color': ['n'],\n",
        "    'bruises': ['f'],\n",
        "    'odor': ['a'],\n",
        "    'gill-attachment': ['f'],\n",
        "    'gill-spacing': ['c'],\n",
        "    'gill-size': ['n'],\n",
        "    'gill-color': ['b'],\n",
        "    'stalk-shape': ['e'],\n",
        "    'stalk-root': ['c'],\n",
        "    'stalk-surface-above-ring': ['s'],\n",
        "    'stalk-surface-below-ring': ['s'],\n",
        "    'stalk-color-above-ring': ['w'],\n",
        "    'stalk-color-below-ring': ['w'],\n",
        "    'veil-type': ['p'],\n",
        "    'veil-color': ['w'],\n",
        "    'ring-number': ['o'],\n",
        "    'ring-type': ['p'],\n",
        "    'spore-print-color': ['n'],\n",
        "    'population': ['c'],\n",
        "    'habitat': ['l']\n",
        "})"
      ],
      "metadata": {
        "id": "iXgR9rCmBj0m"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data_encoded = pd.get_dummies(new_data)\n",
        "new_data_encoded = new_data_encoded.reindex(columns=X.columns, fill_value=0)"
      ],
      "metadata": {
        "id": "bAXwlvCbBmag"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = loaded_model.predict(new_data_encoded.to_numpy().astype('float32'))\n",
        "prediction_class = int(prediction > 0.5)\n",
        "\n",
        "print('Prediction:', prediction_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfWCrDkqD6mi",
        "outputId": "9c84fdda-9202-49ed-e956-69d7e258bc31"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
            "Prediction: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-59-a0145a775ae4>:2: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  prediction_class = int(prediction > 0.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ia2ffHtiBq7q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}