{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ADjJLECAu67A"
      },
      "outputs": [],
      "source": [
        "# Multiclass Classification with TensorFlow: A Step-by-Step Guide Using the Iris Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w7cI8DLZvADS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Dataset: Iris Flower Classification\n",
        "The Iris dataset consists of the following columns:\n",
        "\n",
        "Sepal Length (in cm)\n",
        "Sepal Width (in cm)\n",
        "Petal Length (in cm)\n",
        "Petal Width (in cm)\n",
        "Flower: The species of the flower, which is the target variable.\n",
        "You can download the dataset here."
      ],
      "metadata": {
        "id": "hx_4lsPlvErL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load and Explore the Data\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/fenago/datasets/main/iris.csv')\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(df.head())\n",
        "\n",
        "# Display the column names\n",
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ija1hcQxvA1p",
        "outputId": "a6e025bc-4347-413a-f422-dafb9df86262"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Sepal Length  Sepal Width  Petal Length  Petal Width       Flower\n",
            "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
            "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
            "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
            "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
            "4           5.0          3.6           1.4          0.2  Iris-setosa\n",
            "Index(['Sepal Length', 'Sepal Width', 'Petal Length', 'Petal Width', 'Flower'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Preprocess the Data\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Handle missing values if necessary\n",
        "df = df.dropna()\n",
        "\n",
        "# Separate input features and target variable\n",
        "X = df.drop(columns=['Flower'])  # 'Flower' is the target column\n",
        "y = df['Flower'].values\n",
        "\n",
        "# Encode the target variable y (Flower)\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)  # Converts the three flower types into 0, 1, or 2\n",
        "\n",
        "# Check the number of features\n",
        "n_features = X.shape[1]"
      ],
      "metadata": {
        "id": "Qyb_Q3x2vA4w"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Split the Data into Train and Test Sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split into train and test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "QjEX-hJivA7p"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Define the Model for Multiclass Classification\n",
        "# For a multiclass classification problem, the output layer needs to have softmax activation to predict probabilities for each class. Additionally, the loss function will be categorical cross-entropy, which is standard for multiclass problems.\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', input_shape=(n_features,)))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))  # 3 neurons for 3 classes (Iris-setosa, Iris-versicolor, Iris-virginica)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1Aa4c-uvBCJ",
        "outputId": "5e40c699-8e68-4e75-ea1a-14f8ecc75512"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanation:\n",
        "Input Layer: The input shape corresponds to the number of features in the dataset.\n",
        "Hidden Layers: We have two hidden layers with 10 and 8 neurons respectively, both using ReLU activation.\n",
        "Output Layer: The output layer has 3 neurons (one for each class) and uses softmax activation to output probabilities for each class.\n",
        "Loss Function: Since this is a multiclass classification problem, we use sparse categorical cross-entropy as the loss function. This is appropriate when the target variable is encoded as integers (e.g., 0, 1, 2)."
      ],
      "metadata": {
        "id": "yGCHms1vvr7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Train the Model\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sT_zq74vBXc",
        "outputId": "514c8c6b-a994-49a4-e80b-57aa7d37389d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d7323ea2c20>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Evaluate the Model\n",
        "# Evaluate the model\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test Accuracy: %.3f' % acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4I6nwnFIvBbB",
        "outputId": "cbed2a99-cb36-4300-9fc8-a450d147442c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.980\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Make Predictions\n",
        "# Example prediction\n",
        "import numpy as np\n",
        "\n",
        "sample = np.array([[5.0, 3.6, 1.4, 0.2]])  # Example input for a new flower\n",
        "prediction = model.predict(sample)\n",
        "\n",
        "# Convert the prediction probabilities into a class label\n",
        "predicted_class = np.argmax(prediction, axis=1)\n",
        "print('Predicted class:', predicted_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ax-5GD8VvBem",
        "outputId": "4c118f9c-fced-423d-dc5f-47828e8868c0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "Predicted class: [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "plTtHTsQvBiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pv652fgMvBlm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}