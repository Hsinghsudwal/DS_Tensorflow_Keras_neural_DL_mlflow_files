{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snJS4ejtJ0Y-"
      },
      "outputs": [],
      "source": [
        "# TensorFlow Lite Image Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow tensorflow-hub -qqq"
      ],
      "metadata": {
        "id": "41ZaTNS-KQav"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# Load MobileNetV2 model\n",
        "model_url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\"\n",
        "\n",
        "# Create a Keras layer from the TensorFlow Hub model\n",
        "keras_layer = hub.KerasLayer(model_url)\n",
        "\n",
        "# Build the Sequential model with the Keras layer\n",
        "model = tf.keras.Sequential([keras_layer])\n",
        "\n",
        "# Check model summary\n",
        "model.build([None, 224, 224, 3])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "62wUrt6CKRsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Download and process a sample image\n",
        "!wget -q https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
        "!tar -xf flower_photos.tgz\n",
        "\n",
        "# Load and resize an image\n",
        "img_path = \"flower_photos/roses/12240303_80d87f77a3_n.jpg\"\n",
        "img = Image.open(img_path).resize((224, 224))\n",
        "img_array = np.array(img) / 255.0\n",
        "img_array = img_array[np.newaxis, ...]\n",
        "\n",
        "# Predict using the model\n",
        "predictions = model.predict(img_array)\n",
        "predicted_class = np.argmax(predictions[0])\n",
        "print(f\"Predicted class: {predicted_class}\")\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(img)\n",
        "plt.title(f\"Predicted class: {predicted_class}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "xTg1pLS2KSGO",
        "outputId": "2c82a306-f68a-4490-d38b-9c0fbaeb4e6d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-e29e47a6a796>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Predict using the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mpredicted_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Predicted class: {predicted_class}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the model to TFLite format\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TFLite model to file\n",
        "with open(\"mobilenet_v2.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"TFLite model saved as mobilenet_v2.tflite\")"
      ],
      "metadata": {
        "id": "S7PXYeU7KSL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the TFLite model\n",
        "interpreter = tf.lite.Interpreter(model_path=\"mobilenet_v2.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Load and resize an image\n",
        "img_path = \"flower_photos/roses/12240303_80d87f77a3_n.jpg\"\n",
        "img = Image.open(img_path).resize((224, 224))\n",
        "\n",
        "# Convert image to array and normalize\n",
        "img_array = np.array(img) / 255.0\n",
        "img_array = img_array.astype(np.float32)  # Convert to float32\n",
        "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "\n",
        "# Run inference\n",
        "interpreter.set_tensor(input_details[0]['index'], img_array)\n",
        "interpreter.invoke()\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "predicted_class = np.argmax(output_data[0])\n",
        "print(f\"Predicted class (TFLite): {predicted_class}\")"
      ],
      "metadata": {
        "id": "sH9WMNnZKSPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "# Save the Keras model to disk\n",
        "model.save(\"mobilenet_v2.h5\")\n",
        "\n",
        "# Calculate the model size before conversion\n",
        "model_size_bytes = os.path.getsize(\"mobilenet_v2.h5\")\n",
        "\n",
        "# Calculate the TFLite model size\n",
        "tflite_model_size_bytes = os.path.getsize(\"mobilenet_v2.tflite\")\n",
        "\n",
        "# Convert the sizes to MB\n",
        "model_size_mb = model_size_bytes / (1024 * 1024)\n",
        "tflite_model_size_mb = tflite_model_size_bytes / (1024 * 1024)\n",
        "\n",
        "print(f\"Original Model Size: {model_size_mb:.2f} MB\")\n",
        "print(f\"TFLite Model Size: {tflite_model_size_mb:.2f} MB\")"
      ],
      "metadata": {
        "id": "zZZRm26yKSSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download ImageNet labels\n",
        "!wget -q https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt\n",
        "with open(\"ImageNetLabels.txt\", \"r\") as f:\n",
        "    labels = [line.strip() for line in f.readlines()]"
      ],
      "metadata": {
        "id": "74YnVynYKSVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the TFLite model\n",
        "interpreter = tf.lite.Interpreter(model_path=\"mobilenet_v2.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Load ImageNet labels\n",
        "!wget -q https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt\n",
        "with open(\"ImageNetLabels.txt\", \"r\") as f:\n",
        "    labels = [line.strip() for line in f.readlines()]\n",
        "\n",
        "# Function to run inference, print the result, and show the image\n",
        "def classify_image(image_path):\n",
        "    img = Image.open(image_path).resize((224, 224))\n",
        "    img_array = np.array(img) / 255.0\n",
        "    img_array = img_array.astype(np.float32)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    interpreter.set_tensor(input_details[0]['index'], img_array)\n",
        "    interpreter.invoke()\n",
        "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "    predicted_class = np.argmax(output_data[0])\n",
        "    predicted_label = labels[predicted_class] if predicted_class < len(labels) else \"Unknown\"\n",
        "    print(f\"Predicted class: {predicted_label}\")\n",
        "\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Predicted label: {predicted_label}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Test with other images and show the results\n",
        "classify_image(\"flower_photos/daisy/21652746_cc379e0eea_m.jpg\")\n",
        "# classify_image(\"flower_photos/sunflowers/6953297_8576bf4ea3.jpg\")"
      ],
      "metadata": {
        "id": "dUScPe1ZKScx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}